{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comment toxicity predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ketakee/ketakee.github.io/blob/master/Comment_toxicity_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzVmZ0O9O3i2",
        "colab_type": "text"
      },
      "source": [
        "The goal of this tutorial is to buiild an inbrowser text classifier that works offline as well as online.\n",
        "\n",
        "So that it is easy to deploy, we will use github pages for deploying it. \n",
        "\n",
        "This notebook uses code borrowed from: https://github.com/tensorflow/tfjs-examples/blob/master/sentiment/index.js and from a previous Deep Learning Assignment about text classification in browser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LqUhSn9QSTV",
        "colab_type": "text"
      },
      "source": [
        "At the end of the tutorial, you will be able to build a webpage where in the background colour changes as per the toxicity of the text. This could easily be ported to your website's comment section and you can change it to have the colour of the comment being entered change as per the toxicity of the text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf0ZdlV0Qz1E",
        "colab_type": "text"
      },
      "source": [
        "###Dataset\n",
        "We will use data from the kaggle toxic comment classification challenge. \n",
        "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/rules\n",
        "\n",
        "Go ahead and download the train data from the website. You can upload that file to colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z1Co3gVRDqT",
        "colab_type": "text"
      },
      "source": [
        "Once you've done that, let's set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL3kvgbZRC-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-alpha0\n",
        "!pip install tensorflowjs==1.0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA3PjduuRWy0",
        "colab_type": "text"
      },
      "source": [
        "Let us now set up github parameters so that we can have this notebook talk to github directly instead of manually moving the files around\n",
        "\n",
        "\n",
        "Set up github pages as instructed in :\n",
        "\n",
        "\n",
        "Also, get your token from https://github.com/settings/tokens\n",
        "\n",
        "\n",
        "Remember to make permisions public. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u82J274nQRDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# your github username and email\n",
        "USER_NAME = \"abc\" \n",
        "USER_EMAIL = \"abc@gmail.com\" \n",
        "\n",
        "#Do not publish this token anywhere\n",
        "TOKEN=\"\"\n",
        "# for example, if your user_name is \"foo\", then this notebook will create\n",
        "# a site at \"https://foo.github.io\"\n",
        "SITE_NAME = \"https://foo.github.io\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shKoxhWHOqTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's configure git\n",
        "!git config --global user.email {USER_NAME}\n",
        "!git config --global user.name  {USER_EMAIL}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4z7AVMGSLjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cloning out github repo\n",
        "import os\n",
        "!git clone https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZL3c24VSIzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "repo_path = USER_NAME + '.github.io'\n",
        "os.chdir(repo_path)\n",
        "!git pull\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGOaN9LySdTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Create a folder for your site\n",
        "# project_path = os.path.join(os.getcwd())\n",
        "# if not os.path.exists(project_path): \n",
        "#   os.mkdir(project_path)\n",
        "# os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eeRPm91S0xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DO NOT MODIFY\n",
        "MODEL_DIR = os.path.join(project_path, \"model_js\")\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "  os.mkdir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C5iRRwQS6YQ",
        "colab_type": "text"
      },
      "source": [
        "#Model\n",
        "Now that we are done with housekeeping, we can train our model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-xAZPkvS3MN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the data\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK6aRGE2XOZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"/content/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is7LbPc2TClK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's get the toxic and non toxic comments\n",
        "toxic=df[df[\"toxic\"]==1][\"comment_text\"]\n",
        "non_toxic=df[df[\"toxic\"]==0][\"comment_text\"]\n",
        "\n",
        "#converting them to lists\n",
        "#taking 10k of both classes randomly:\n",
        "toxic=list(toxic)\n",
        "non_toxic=list(non_toxic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klH3vHkNTeYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Randomly taking 7000 sentences from each for training and 3000 sentences from each for testing\n",
        "from random import shuffle\n",
        "shuffle(toxic)\n",
        "shuffle(non_toxic)\n",
        "\n",
        "toxic_train=toxic[:7000]\n",
        "non_toxic_train = non_toxic[:7000]\n",
        "toxic_test=toxic[7000:10000]\n",
        "non_toxic_test = non_toxic[7000:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A0bliOLTsgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's create training and testing datasets\n",
        "\n",
        "x_train=toxic_train + non_toxic_train\n",
        "y_train=[0,]*len(toxic_train) + [1,]*len(non_toxic_train)\n",
        "x_test=toxic_test + non_toxic_test\n",
        "y_test=[0,]*len(toxic_test) + [1,]*len(non_toxic_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5utqHVbsT0SM",
        "colab_type": "text"
      },
      "source": [
        "#Text Pre-processing\n",
        "Now that we have our text data, let's set up the text pre-processing steps\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJq00k6JTycn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len_vec = [len(elem) for elem in x_train] #[len(elem) for elem in x_test] + [len(elem) for elem in x_val] \n",
        "max_len = 40\n",
        "num_words = 10000\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# Fit the tokenizer on the training data\n",
        "t = Tokenizer(num_words=num_words,  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
        "t.fit_on_texts(x_train+x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx7AZSp3WdZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LEt's take a look at the dictionary\n",
        "print(t.word_index)\n",
        "print(len(t.word_index.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXo1gyx-WhDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The metadata will help load things when we port the model to browser and load it using js. \n",
        "#As a rule of thumb, anything you will need to maintain or share, such as word mappings, should be stores in the metadata. This can be as small or as big as you like\n",
        "metadata = {\n",
        "  'word_index': t.word_index,\n",
        "  'max_len': max_len,\n",
        "  'vocabulary_size': num_words,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k99ueo9MXFGj",
        "colab_type": "text"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXQbDHMXXDDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size = 16\n",
        "n_classes = 2\n",
        "epochs = 20\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
        "# model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dropout(0.6))\n",
        "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07GqozCRXG_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preparing the training data\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = t.texts_to_sequences(x_train)\n",
        "x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\n",
        "print(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCwoFya-XLCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, np.array(y_train), epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHEz_3gQXULp",
        "colab_type": "text"
      },
      "source": [
        "Let's test it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5EL70gSXQi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test_example = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
        "test_example = non_toxic[18000]\n",
        "x_test_ex = t.texts_to_sequences([test_example])\n",
        "x_test_ex = pad_sequences(x_test_ex, maxlen=max_len, padding='post')\n",
        "print(x_test_ex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpIOs6QyXVJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9waDhmQDXZSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0 - homer, 1- moby dick, 2- tale of two cities, 3- pride and prejudice\n",
        "preds = model.predict(x_test_ex)\n",
        "print(preds)\n",
        "print(np.argmax(preds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amEnfBkDXbOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = t.texts_to_sequences(x_test)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5t_Ua6gXe8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(x_test,np.array(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtD7hHbfXfq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4hsckC0Xhha",
        "colab_type": "text"
      },
      "source": [
        "#Convert the model\n",
        "\n",
        "Now that we have our complete model, we are ready to port it to tensorflow js"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XloInd4XjoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "#Let's write the metadata to a json file\n",
        "metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')\n",
        "json.dump(metadata, open(metadata_json_path, 'wt'))\n",
        "\n",
        "#Converting the model and saving it\n",
        "tfjs.converters.save_keras_model(model, MODEL_DIR)\n",
        "print('\\nSaved model artifcats in directory: %s' % MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JVMHcdeXpvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_html = \"\"\"\n",
        "<!doctype html>\n",
        "\n",
        "<body>\n",
        "  <style>\n",
        "    #textfield {\n",
        "      font-size: 120%;\n",
        "      width: 60%;\n",
        "      height: 200px;\n",
        "    }\n",
        "  </style>\n",
        "  <h1>\n",
        "    Title\n",
        "  </h1>\n",
        "  <hr>\n",
        "  <div class=\"create-model\">\n",
        "    <button id=\"load-model\" style=\"display:none\">Load model</button>\n",
        "  </div>\n",
        "  <div>\n",
        "    <div>\n",
        "      <span>Vocabulary size: </span>\n",
        "      <span id=\"vocabularySize\"></span>\n",
        "    </div>\n",
        "    <div>\n",
        "      <span>Max length: </span>\n",
        "      <span id=\"maxLen\"></span>\n",
        "    </div>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <textarea id=\"text-entry\"></textarea>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <span id=\"status\">Standing by.</span>\n",
        "  </div>\n",
        "\n",
        "  <script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>\n",
        "  <script src='index.js'></script>\n",
        "</body>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FtM1tbBYETv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_js = \"\"\"\n",
        "\n",
        "const HOSTED_URLS = {\n",
        "  model:\n",
        "      'model_js/model.json',\n",
        "  metadata:\n",
        "      'model_js/metadata.json'\n",
        "};\n",
        "\n",
        "function status(statusText) {\n",
        "  console.log(statusText);\n",
        "  document.getElementById('status').textContent = statusText;\n",
        "}\n",
        "\n",
        "function showMetadata(metadataJSON) {\n",
        "  document.getElementById('vocabularySize').textContent =\n",
        "      metadataJSON['vocabulary_size'];\n",
        "  document.getElementById('maxLen').textContent =\n",
        "      metadataJSON['max_len'];\n",
        "}\n",
        "\n",
        "function settextField(text, predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.value = text;\n",
        "  doPredict(predict);\n",
        "}\n",
        "\n",
        "function setPredictFunction(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.addEventListener('input', () => doPredict(predict));\n",
        "}\n",
        "\n",
        "function disableLoadModelButtons() {\n",
        "  document.getElementById('load-model').style.display = 'none';\n",
        "}\n",
        "\n",
        "function doPredict(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  const result = predict(textField.value);\n",
        "  console.log(result);\n",
        "  score_string = \"Class scores: \";\n",
        "  document.body.style.background = 'rgb(' + ((result.score[0]) *256) +',' + (result.score[1] *256) +',0)';\n",
        "//   ${result.score[0]}*256,${result.score[1]}*256,0)\";\n",
        "//   document.body.style.background = 'rgb($result.score[0]*256,$result.score[1]*256,0)';\n",
        "  for (var x in result.score) {\n",
        "    score_string += x + \" :  \" + result.score[x].toFixed(3) + \", \"\n",
        "  }\n",
        "  //console.log(score_string);\n",
        "  status(\n",
        "      score_string + ' elapsed: ' + result.elapsed.toFixed(3) + ' ms)');\n",
        "}\n",
        "\n",
        "function prepUI(predict) {\n",
        "  setPredictFunction(predict);\n",
        "  const testExampleSelect = document.getElementById('example-select');\n",
        "  testExampleSelect.addEventListener('change', () => {\n",
        "    settextField(examples[testExampleSelect.value], predict);\n",
        "  });\n",
        "  settextField(examples['example1'], predict);\n",
        "}\n",
        "\n",
        "async function urlExists(url) {\n",
        "  status('Testing url ' + url);\n",
        "  try {\n",
        "    const response = await fetch(url, {method: 'HEAD'});\n",
        "    return response.ok;\n",
        "  } catch (err) {\n",
        "    return false;\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedPretrainedModel(url) {\n",
        "  status('Loading pretrained model from ' + url);\n",
        "  try {\n",
        "    const model = await tf.loadLayersModel(url);\n",
        "    status('Done loading pretrained model.');\n",
        "    disableLoadModelButtons();\n",
        "    return model;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading pretrained model failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedMetadata(url) {\n",
        "  status('Loading metadata from ' + url);\n",
        "  try {\n",
        "    const metadataJson = await fetch(url);\n",
        "    const metadata = await metadataJson.json();\n",
        "    status('Done loading metadata.');\n",
        "    return metadata;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading metadata failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "class Classifier {\n",
        "\n",
        "  async init(urls) {\n",
        "    this.urls = urls;\n",
        "    this.model = await loadHostedPretrainedModel(urls.model);\n",
        "    await this.loadMetadata();\n",
        "    return this;\n",
        "  }\n",
        "\n",
        "  async loadMetadata() {\n",
        "    const metadata =\n",
        "        await loadHostedMetadata(this.urls.metadata);\n",
        "    showMetadata(metadata);\n",
        "    this.maxLen = metadata['max_len'];\n",
        "    console.log('maxLen = ' + this.maxLen);\n",
        "    this.wordIndex = metadata['word_index']\n",
        "  }\n",
        "\n",
        "  predict(text) {\n",
        "    // Convert to lower case and remove all punctuations.\n",
        "    const inputText =\n",
        "        text.trim().toLowerCase().replace(/(\\.|\\,|\\!)/g, '').split(' ');\n",
        "    // Look up word indices.\n",
        "    const inputBuffer = tf.buffer([1, this.maxLen], 'float32');\n",
        "    for (let i = 0; i < inputText.length; ++i) {\n",
        "      const word = inputText[i];\n",
        "      inputBuffer.set(this.wordIndex[word], 0, i);\n",
        "      //console.log(word, this.wordIndex[word], inputBuffer);\n",
        "    }\n",
        "    const input = inputBuffer.toTensor();\n",
        "    //console.log(input);\n",
        "\n",
        "    status('Running inference');\n",
        "    const beginMs = performance.now();\n",
        "    const predictOut = this.model.predict(input);\n",
        "    //console.log(predictOut.dataSync());\n",
        "    const score = predictOut.dataSync();//[0];\n",
        "    predictOut.dispose();\n",
        "    const endMs = performance.now();\n",
        "\n",
        "    return {score: score, elapsed: (endMs - beginMs)};\n",
        "  }\n",
        "};\n",
        "\n",
        "async function setup() {\n",
        "  if (await urlExists(HOSTED_URLS.model)) {\n",
        "    status('Model available: ' + HOSTED_URLS.model);\n",
        "    const button = document.getElementById('load-model');\n",
        "    button.addEventListener('click', async () => {\n",
        "      const predictor = await new Classifier().init(HOSTED_URLS);\n",
        "      prepUI(x => predictor.predict(x));\n",
        "    });\n",
        "    button.style.display = 'inline-block';\n",
        "  }\n",
        "\n",
        "  status('Standing by.');\n",
        "}\n",
        "\n",
        "setup();\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGQDzXZhYHtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('index.html','w') as f:\n",
        "  f.write(index_html)\n",
        "  \n",
        "with open('index.js','w') as f:\n",
        "  f.write(index_js)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRweArdJYIcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git add . \n",
        "!git commit -m \"colab -> github\"\n",
        "!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{USER_NAME}.github.io/ master"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d10J6xEWYMj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Now, visit https://%s.github.io/\" % (USER_NAME))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}